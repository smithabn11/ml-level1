{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning lab\n",
    "\n",
    "Welcome to the world of machine learning. In this notebook let's explore what is machine learning and apply it to solve a classification problem.\n",
    "\n",
    "## GOAL of this lab\n",
    "\n",
    "You will learn:\n",
    "1. What is machine learning\n",
    "2. Different types of machine learning problems\n",
    "3. Understanding data and output used for machine learning using an sample data\n",
    "4. Different machine learning algorithms\n",
    "3. Learn how to use a machine learning algorithm to solve a classification problem\n",
    "\n",
    "\n",
    "In addition, you will use \n",
    "1. python 3: Python is an interpreted, high-level, general-purpose programming language\n",
    "2. scipy: SciPy is a free and open-source Python library used for scientific computing and technical computing. SciPy contains modules for optimization, linear algebra, integration, interpolation, special functions, FFT, signal and image processing, ODE solvers and other tasks common in science and engineering.\n",
    "3. numpy: NumPy is a library for the Python programming language, adding support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays.\n",
    "4. matplotlib: Matplotlib is a Python 2D plotting library which produces publication quality figures in a variety of hardcopy formats and interactive environments across platforms\n",
    "5. pandas:  Pandas is a software library written for the Python programming language for data manipulation and analysis. In particular, it offers data structures and operations for manipulating numerical tables and time series\n",
    "6. sklearn: Scikit-learn (formerly scikits.learn) is a free software machine learning library for the Python programming language.[3] It features various classification, regression and clustering algorithms including support vector machines, random forests, gradient boosting, k-means and DBSCAN, and is designed to interoperate with the Python numerical and scientific libraries NumPy and SciPy\n",
    "\n",
    "These python libraries are installed in your virtual environment using pip and requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is machine learning ?\n",
    "Machine learning (ML) describes algorithms that look at data and correct output for that data and learn from it.\n",
    "A ML program will try to learn the relationship between input data and the output.\n",
    "\n",
    "A machine learning program:\n",
    "1. Extracts the features of the dataset (e.g., shape or color) for a given problem (e.g., separating apples and oranges)\n",
    "2. Uses the observed features and correct output (also called 'labels') to learn the results (e.g., it is an apple or it is an orange).\n",
    "3. Saves the observed results as a machine learning model for later use.\n",
    "4. Uses the saved results in the machine learning model to predict the output for a new data instance (is this an apple or an orange?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Click and run the below code cell to learn more about features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e720db8787684a6d8fe638406d108f33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<b> Does Machine learning </b> <i>always</i> <b>require output accompanying the data to learn ? </…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7680e7a28db41bc9ad32f3da704ff1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Yes', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d92400e5ee5f4bc6aa8318f50f7976df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='No', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c336844bc3ce46ef91cc06afb00fc075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Box(children=(HTML(value=''),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "REPO_PATH = ''\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "import widget_utils\n",
    "\n",
    "widget_utils.machine_learning()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a feature in machine learning?\n",
    "\n",
    "A feature is an individual measurable property or characteristic of a phenomenon being observed. For example, an apple is red, green, or pink.  A banana is yellow.  An apple is round.  A banana is oblong and tapered at the ends. \n",
    "[Reference](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=2ahUKEwjY9KX3pKLeAhUN7p8KHTbwAMUQFjABegQIChAB&url=https%3A%2F%2Fwww.springer.com%2Fus%2Fbook%2F9780387310732&usg=AOvVaw19ZfKiiH_u4x4lnbqIQ-Zp)\n",
    "\n",
    "Let's consider a task of separating green apples vs oranges from a box which contains both. There are a few properties like shape, weight, color which we can use to separate them. These properties are the features for the machine learning task. Let's see what makes a good feature below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Click and run the below code cell to learn more about features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "424bbab3f50e44529e9bab0ceff6b681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<b> Click on a below button to select a good feature to distinguish between green apples vs orange…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "166dcfbdaf0f48249b0fc89f00c26713",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='shape', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58e93250294f406c9fc741c1017909c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='weight', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8a644d07a834d7ab08c810a7791d761",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='color', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "519fc0e01f4e42bcbb728efcd6deae03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=''), Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x052\\x00\\x00\\x00\\x10\\…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "widget_utils.feature_selection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2 types of supervised machine learning:\n",
    "1. Classification\n",
    "2. Regression\n",
    "\n",
    "The problem presented above (separating green apples vs oranges) is a classification task.\n",
    "\n",
    "An example of a regression task is determining the <b>price</b> of an apple using all the appropriate features that contribute to the price.  A machine learning program will use features like weight, quality, source, season, price of alternatives, availability, etc. to determine an approximate price.\n",
    "\n",
    "This lab is going to demonstrate a classification task using Iris flower dataset. The data set consists of 50 samples from each of three species of Iris flower (Iris setosa, Iris virginica and Iris versicolor). Four features were measured from each sample: the length and the width of the sepals and petals, in centimeters. Based on the combination of these four features we will develop a machine learning model to distinguish the species from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries\n",
    "\n",
    "Before we start let's import the libraries necessary for this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the libraries should load without any error. If there is an error Module Not Found then that library is missing in your virtual environment and need to install that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'species']\n",
    "dataset = pandas.read_csv('data/iris_dataset.csv', skiprows=1, names=names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset should load without any errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try to look at data.\n",
    "\n",
    "In this step we are going to take a look at the data a few different ways:\n",
    "\n",
    "1. Dimensions of the dataset.\n",
    "2. Peek at the data itself.\n",
    "3. Statistical summary of all attributes.\n",
    "4. Breakdown of the data by the class variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dimensions of Dataset\n",
    "We can get a quick idea of how many instances (rows) and how many attributes (columns) the data contains with the shape property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 5)\n"
     ]
    }
   ],
   "source": [
    "# shape\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above you will see that the dataset has 150 instances and 5 attributes. Next let's see first few rows of data to and distinguish between features and the output class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sepal-length  sepal-width  petal-length  petal-width species\n",
      "0            5.1          3.5           1.4          0.2  setosa\n",
      "1            4.9          3.0           1.4          0.2  setosa\n",
      "2            4.7          3.2           1.3          0.2  setosa\n",
      "3            4.6          3.1           1.5          0.2  setosa\n",
      "4            5.0          3.6           1.4          0.2  setosa\n",
      "5            5.4          3.9           1.7          0.4  setosa\n",
      "6            4.6          3.4           1.4          0.3  setosa\n",
      "7            5.0          3.4           1.5          0.2  setosa\n",
      "8            4.4          2.9           1.4          0.2  setosa\n",
      "9            4.9          3.1           1.5          0.1  setosa\n",
      "10           5.4          3.7           1.5          0.2  setosa\n",
      "11           4.8          3.4           1.6          0.2  setosa\n",
      "12           4.8          3.0           1.4          0.1  setosa\n",
      "13           4.3          3.0           1.1          0.1  setosa\n",
      "14           5.8          4.0           1.2          0.2  setosa\n",
      "15           5.7          4.4           1.5          0.4  setosa\n",
      "16           5.4          3.9           1.3          0.4  setosa\n",
      "17           5.1          3.5           1.4          0.3  setosa\n",
      "18           5.7          3.8           1.7          0.3  setosa\n",
      "19           5.1          3.8           1.5          0.3  setosa\n"
     ]
    }
   ],
   "source": [
    "# head\n",
    "print(dataset.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistical Summary\n",
    "\n",
    "Now we can take a look at a summary of each attribute.\n",
    "This includes the count, mean, the min and max values as well as some percentiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       sepal-length  sepal-width  petal-length  petal-width\n",
      "count    150.000000   150.000000    150.000000   150.000000\n",
      "mean       5.843333     3.054000      3.758667     1.198667\n",
      "std        0.828066     0.433594      1.764420     0.763161\n",
      "min        4.300000     2.000000      1.000000     0.100000\n",
      "25%        5.100000     2.800000      1.600000     0.300000\n",
      "50%        5.800000     3.000000      4.350000     1.300000\n",
      "75%        6.400000     3.300000      5.100000     1.800000\n",
      "max        7.900000     4.400000      6.900000     2.500000\n"
     ]
    }
   ],
   "source": [
    "# descriptions\n",
    "print(dataset.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that all of the numerical values have the same scale (centimeters) and similar ranges between 0 and 8 centimeters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "710ef82056434479b7b53ff5b83984ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<b> Click all the features used in this dataset to distinguish different Iris flowers </b> <br> Cl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ed6b367e8304ffbab60a0b1d75e0716",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SelectMultiple(options=('sepal-length', 'species', 'sepal-width', 'petal-length', 'petal-width'), value=())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "widget_utils.iris_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class Distribution\n",
    "Let’s now take a look at the number of instances (rows) that belong to each class. We can view this as an absolute count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "species\n",
      "setosa        50\n",
      "versicolor    50\n",
      "virginica     50\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# class distribution\n",
    "print(dataset.groupby('species').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's use a few Machine learning algorithms to solve our problem\n",
    "\n",
    "Now it is time to create some models of the data and estimate their accuracy on unseen data.\n",
    "\n",
    "Here is what we are going to cover in this step:\n",
    "\n",
    "    1. Separate out a validation dataset.\n",
    "    2. Set-up the test harness to use 10-fold cross validation.\n",
    "    3. Build 5 different models to predict species from flower measurements\n",
    "    4. Select the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Validation Dataset\n",
    "\n",
    "We need to know that the model we created is any good.\n",
    "\n",
    "Later, we will use statistical methods to estimate the accuracy of the models that we create on unseen data. We also want a more concrete estimate of the accuracy of the best model on unseen data by evaluating it on actual unseen data.\n",
    "\n",
    "That is, we are going to hold back some data that the algorithms will not get to see and we will use this data to get a second and independent idea of how accurate the best model might actually be.\n",
    "\n",
    "We will split the loaded dataset into two, 80% of which we will use to train our models and 20% that we will hold back as a validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split-out validation dataset\n",
    "array = dataset.values\n",
    "X = array[:,0:4]\n",
    "Y = array[:,4]\n",
    "validation_size = 0.20\n",
    "seed = 7\n",
    "X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(X, Y, test_size=validation_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now have training data in the X_train and Y_train for preparing models and a X_validation and Y_validation sets that we can use later for evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During training we need a subset of data to see how well we are able to learn as training progresses i.e. we should be able to calculate our accuracy. To do this we can use k-fold cross validation. Let's explain this below.\n",
    "\n",
    "We will use 10-fold cross validation to estimate accuracy.\n",
    "\n",
    "This will split our training set into 10 parts, train on 9 and test on 1 and repeat for all combinations of train-test splits during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test options and evaluation metric\n",
    "seed = 7\n",
    "scoring = 'accuracy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The specific random seed above does not matter, learn more about pseudorandom number generators here:\n",
    "\n",
    "Introduction to Random Number Generators for Machine Learning in Python\n",
    "\n",
    "We are using the metric of ‘accuracy‘ to evaluate models. This is a ratio of the number of correctly predicted instances in divided by the total number of instances in the dataset multiplied by 100 to give a percentage (e.g. 95% accurate). We will be using the scoring variable when we run build and evaluate each model next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don’t know which algorithms would be good on this problem or what configurations to use. We get an idea from the plots that some of the classes are partially linearly separable in some dimensions, so we are expecting generally good results.\n",
    "\n",
    "Let’s evaluate 2 different algorithms:\n",
    "\n",
    "1. Logistic Regression (LR)\n",
    "2. K-Nearest Neighbors (KNN).\n",
    "\n",
    "This is a good mixture of simple linear (LR), nonlinear (KNN) algorithms. We reset the random number seed before each run to ensure that the evaluation of each algorithm is performed using exactly the same data splits. It ensures the results are directly comparable.\n",
    "\n",
    "Let’s build and evaluate our models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.966667 (0.040825)\n",
      "KNN: 0.983333 (0.033333)\n"
     ]
    }
   ],
   "source": [
    "# Spot Check Algorithms\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr')))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "    cv_results = model_selection.cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have 2 models and accuracy estimations for each. We need to compare the models to each other and select the most accurate.\n",
    "\n",
    "Running the example above, we get the following raw results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KNN algorithm is very simple and was an accurate model based on our tests. Now we want to get an idea of the accuracy of the model on our validation set.\n",
    "\n",
    "This will give us an independent final check on the accuracy of the best model. It is valuable to keep a validation set just in case you made a slip during training, such as overfitting to the training set or a data leak. Both will result in an overly optimistic result.\n",
    "\n",
    "We can run the KNN model directly on the validation set and summarize the results as a final accuracy score, a confusion matrix and a classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n",
      "[[ 7  0  0]\n",
      " [ 0 11  1]\n",
      " [ 0  2  9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00         7\n",
      "  versicolor       0.85      0.92      0.88        12\n",
      "   virginica       0.90      0.82      0.86        11\n",
      "\n",
      "   micro avg       0.90      0.90      0.90        30\n",
      "   macro avg       0.92      0.91      0.91        30\n",
      "weighted avg       0.90      0.90      0.90        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on validation dataset\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, Y_train)\n",
    "predictions = knn.predict(X_validation)\n",
    "print(accuracy_score(Y_validation, predictions))\n",
    "print(confusion_matrix(Y_validation, predictions))\n",
    "print(classification_report(Y_validation, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the accuracy is 0.9 or 90%. The confusion matrix provides an indication of the three errors made. Finally, the classification report provides a breakdown of each class by precision, recall, f1-score and support showing excellent results (granted the validation dataset was small)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n",
      "[[ 7  0  0]\n",
      " [ 0  7  5]\n",
      " [ 0  1 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00         7\n",
      "  versicolor       0.88      0.58      0.70        12\n",
      "   virginica       0.67      0.91      0.77        11\n",
      "\n",
      "   micro avg       0.80      0.80      0.80        30\n",
      "   macro avg       0.85      0.83      0.82        30\n",
      "weighted avg       0.83      0.80      0.80        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(solver='liblinear', multi_class='ovr')\n",
    "lr.fit(X_train, Y_train)\n",
    "predictions = lr.predict(X_validation)\n",
    "print(accuracy_score(Y_validation, predictions))\n",
    "print(confusion_matrix(Y_validation, predictions))\n",
    "print(classification_report(Y_validation, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
